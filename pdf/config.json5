{
    // The workbench consists of UI connected to a number of external plugins,
    // which are organized into 'parsers', 'file_detail_views', and
    // 'decision_views'.  These are  supported through the defining of the
    // "build" environment.
    //
    // The reason this is a custom format instead of a standard Dockerfile is
    // so that the entire deployment might be specified in a single location.
    // Dockerfile is necessary because many external plugins have their own
    // requirements, etc.
    //
    // Everything in this file except 'build' is live-reloaded when used with
    // the --development flag. This applies mostly to plugins, but can also
    // apply to 'parsers' when the DB is reset through the UI (use on small
    // collections of files only).


    // The name of the docker image to be produced.
    name: 'galois-workbench-pdf',

    // If needbe, a program may be specified here. The given program can take
    // only '<inputFile>' as a special argument, and is expected to output (to
    // stdout) a transformed version of the input file, which is the content
    // that will actually be inspected by the FAW.
    file_transform: null, /*{
      version: '1',
      exec: ['echo', '<inputFile>'],
    },*/

    // Seconds, per parser, in which each parser must finish executing.
    parserDefaultTimeout: 60,
    parsers: {
        // Example of running the unix command 'file' on each file to gather
        // information.
        "example-file": {
            // Any disabled parser has no effect -- comment this line to enable
            disabled: true,
            exec: ['file', '<inputFile>'],
            // Most parsers can fail, and that's OK. Once in awhile though, it
            // is useful to specify a parser which will only ever fail
            // transiently, and must be retried if failed. Set to true for this
            // behavior.
            mustSucceed: false,
            version: '1',
            parse: {
                type: 'regex-counter',
                version: '1',
                stdstar: {
                  // Report all lines of stdout and stderr, but strip numbers.
                  '.*': {
                    nameReplace: {
                      '[0-9]': '',
                    },
                  },
                },
            },
        },

        // Definitions should follow old `invokers.cfg`, BUT eventually we also
        // want to specify `pdf-etl-parse` toolchain here.

        'pdfid': {
            disabled: true,
            exec: ['python3', 'lib/pdfid_v0_2_7/pdfid.py',
                // FIXME: a bit ugly that we have a relative path above
                '-e', '<inputFile>'],
            version: 'pdfid_v0_2_7__py3',
            parse: {
                type: 'regex-counter',
                version: '1',
                stdout: {
                    'pdf header:(.*)': {
                        nameGroup: 'PDF Header',
                    },

                    '^(.*?[Ee]ntropy.*):\\s*(\\d\\.\\d+)\\s+\\(\\s*(\\d+) bytes\\)$': {
                        nameGroup: 1,
                        countGroup: 2,
                    },

                    '^(.+?)[ \\t]+(\\d+)$': {
                        nameGroup: 1,
                        countGroup: 2,
                        countAsMissing: ['0', '0.', '0.0'],
                    },

                    '^[ \\t]*D:(\\d{14}).*(/[a-zA-Z0-9]+)$': {
                        nameGroup: 'Date: \\g<2>',
                    },

                    'PDFiD.*': {
                        countReplace: {'.*': ''},
                    },

                    '(.*)': {
                        nameGroup: 1,
                        nameReplace: {'[0-9]': ''},
                    },
                },
                stderr: {},
            },
        },

    },

    pipelines: {
      // See ml_test/config.json5 for example.
    },

    // May also specify a plaintext file to avoid needed to format as JSON5:
    // decision_default: {file: 'file_path_relative_to_config.txt'},
    decision_default: {file: 'dsl.txt'},

    decision_views: {
        /** Example decision process which documents API.

            See also build -> stages -> final, where the requirements for this
            plugin get installed.
            */
        qpdf_plugin: {
            // How this decider shows in the UI
            label: "Example - Allow QPDF Exit Code 0",
            // How this decider gets executed. 'program' is only option
            type: 'program',
            /** The commandline for invoking this program.

                stdout is expected to be a streaming JSON format, where each
                line is an object with keys:

                    * testfile: Full file name.
                    * info: Array of `'text'` or `{"description": "text",
                        "offset": <location specification>}`.
                    * <any>: A feature which should be specified in the
                        workbench DSL, in order to filter/interact with the
                        attribute.

                Lines not beginning with '{' are ignored.

                Options:

                * <filesPath> -- Path to folder containing files, in case this
                    decision process needs to look at the raw file data.

                * <jsonArguments> -- Receives a JSON object which contains any
                    parameters passed to this decider's URL. The workbench
                    itself will NOT use this feature, but the `<outputHtml>`
                    may leverage the value of `<workbenchApiUrl>` to re-run
                    a decision with new parameters, via e.g.
                    `workbenchApiUrl + '/redecide?arg1=1&arg2=2'` to
                    re-trigger this decider with
                    `jsonArguments={'arg1': '1', 'arg2': '2'}`.

                * <mongo> -- "host:port/db" pointer to the mongo database.

                    There are several available collections; the easiest to use
                    is `statsbyfile`, and the most detailed is `rawinvocations`.

                    Available collections:
                        * statsbyfile -- `_id` is path to file within
                            <filesPath>. Outside of that, each key is a
                            feature present in the file, and each value is
                            undefined at the moment.
                        * rawinvocations -- Keyed by `doc['invoker']['invName']`
                            and `doc['file']` (which is `filesPath + '/' + file`),
                            rawinvocations contains the raw parser stdout, stderr,
                            and exit code attained by running a parser.

                            Not for the faint of heart.

                * <outputHtml> -- Receives file path for customized debug display.
                    This file will be consumed and put into an iframe.

                * <workbenchApiUrl> -- Receives prefix for URL to access a file;
                    e.g., `url + 'showFile?id=' + statsbyfile['_id']` is the `href`
                    value for a link in the `outputHtml` file which would
                    lead the workbench to display the given file.

                    APIs:
                        * redecide?arg1=1&arg2=2&... - Re-run this decision
                            plugin, with `<jsonArguments>` containing a dict:
                            `{'arg1': '1', 'arg2': '2'}`.
                        * redetail?arg1=1&... - Re-run current file detail view
                            plugin, with `<jsonArguments>` containing a dict:
                            `{'arg1': '1', ...}`.
                        * showFile?id=file - Show details for `file` in the
                            workbench.

                    Javascript may be used to send arguments more complicated
                    than may be passed over a URL (as POST body).

                */
            exec: ['python3', 'qpdf_plugin/main.py', "<outputHtml>", "<workbenchApiUrl>", "<jsonArguments>"],
            /** Standard input passed to the program specified by `exec`. This is
                provided as a convenience, to prevent decision programs from
                needing to interact with mongo.

                Template substitution options:
                * <referenceDecisions> Each line is a JSON object, whose value
                    is one row of the current reference decision list.
                * <statsbyfile> Each line is a JSON object:
                    `{"_id": "file1", "feature1": <any>, ...}`.
                */
            execStdin: '<statsbyfile>',
        },

        vue_plugin: {
            label: 'Fancy Vue plugin',
            type: 'program',
            exec: ['python3', 'vue_plugin/main.py', '<outputHtml>',
                '<workbenchApiUrl>', '<jsonArguments>'],
            execStdin: '<statsbyfile>',
        },

        example2: {
            label: 'Flip reference decisions',
            type: 'program',
            exec: ['python3', '-c', "\
import json, sys \n\
with open(sys.argv[1], 'w') as html: \n\
    html.write('<html><body>') \n\
    in_refs = False \n\
    for line in sys.stdin: \n\
        if not in_refs: \n\
            if line == 'refs\\n': \n\
                in_refs = True \n\
        else: \n\
            o = json.loads(line) \n\
            o['status'] = 'valid' if o['status'] == 'rejected' else 'rejected' \n\
            print(json.dumps(o)) \n\
",
                    '<outputHtml>'],
            execStdin: 'lines\nblah\nrefs\n<referenceDecisions>',
        },
    },

    file_detail_views: {
        viewer: {
            label: 'View PDF in browser',
            type: 'program_to_html',
            exec: ['cat', '<inputFile>'],
            // Applications may also produce non-HTML content displayable in a browser,
            // as long as the MIME type gets set. Test this in Chrome; Firefox appears
            // to have better MIME type inference, and may correctly show the content
            // even without this field.
            outputMimeType: 'application/pdf',
        },
    },

    build: {
        // The software environment must be defined.  It optionally may be grouped
        // into different build stages, which map to stages in docker.
        stages: {
            // Defining docker stages -- there MUST be a 'base' stage, which is
            // automatically included in final output.
            // Other stages with `copy_output` defined will also be included
            // in the final output.
            // Stages are written to the Dockerfile in order.  Most plugins will
            // only need to modify the 'final' stage's commands.

            // The base stage must have a 'from', which defines the base
            // image.  Other stages may also specify 'from'; otherwise,
            // `from: 'base'` is implied.

            // The 'final' stage is special -- it only allows commands, and
            // any commands executed are executed only in the final image.

            // Each stage may have a 'copy_output', which defines the outputs
            // produced by the stage.  The key is the absolute path to the file
            // or directory to be copied (may have asterisk wildcards), and the
            // value is either `true` to copy to the same absolute path, or a
            // new copy destination.  When specifying a new destination,
            // if that destination is a directory, append a trailing slash.

            // Each stage may have a 'commands', which specifies commands to
            // run.

            // Optimization note: every time 'base' gets updated, there may
            // be a long recompilation process. Ideally, most development work
            // should not touch 'base'. One way around this is for other images
            // to specify their own 'from' keys.

            // All `commands` get run through `str.format()` in python, with
            // `dist` mapping to the folder with config.json5 on the host system
            // (outside of docker), and `disttarg` mapping to `/home/dist` path
            // within docker for the same folder. These are both important for
            // copying, e.g., requirements.txt

            base: {
                'from': 'ubuntu:20.04',
                commands: [
                    'ENV DEBIAN_FRONTEND=noninteractive',

                    // Note that we will *also* install a newer version of poppler in /usr/local/bin
                    'RUN apt-get update && apt-get install -y \
                        libopenjp2-7 \
                        ',

                    // Requirements for building poppler utils from source
                    // No effort has been made to distinguish what's required only
                    // for the build, so we install them all up front.
                    'RUN apt-get update && apt-get install -y \
                        uuid-dev \
                        gperf \
                        libtool \
                        gettext \
                        autopoint \
                        autoconf \
                        python3-dev \
                        libssl-dev \
                        cmake \
                        libfreetype6-dev \
                        libxcb-composite0-dev \
                        libxml2-dev \
                        ',
                    // Needed to build pdftocairo target in poppler
                    'RUN apt-get update && apt-get install -y \
                        libcairo2-dev \
                        ',
                    // Ensure poppler has fonts installed and available; installs both MS fonts and
                    // uses a nuclear option to select all available ubuntu fonts packages.
                    'RUN echo ttf-mscorefonts-installer msttcorefonts/accepted-mscorefonts-eula select true | debconf-set-selections',
                    "RUN apt-get update \
                      && apt-get install -y ttf-mscorefonts-installer ttf-dejavu-core \
                      && apt-cache search -n ^fonts- \
                        | awk '{{print $1}}' \
                        | grep -v fonts-mathematica \
                        | xargs apt-get install -y \
                      ",
                    // Schizo test additionally requires a few packages for opencv2
                    'RUN apt-get update && apt-get install -y ffmpeg libsm6 libxext6',
                ],
            },

            // final is a special stage which runs in the final image.  Useful
            // for installing dependencies for downstream tools, without needing
            // to rebuild all of the other workbench internals.
            final: {
                commands: [
                    // Interestingly, some packages (e.g. opencv-python) require
                    // an updated pip.
                    'RUN pip3 install --upgrade pip',

                    // Note that {dist} gets replaced in Dockerfile commands with
                    // the directory containing `config.json5`
                    // Similarly, {disttarg} gets rewritten with '/home/dist', BUT
                    // it supports modular configs (those in child folders).
                    'COPY {dist}/qpdf_plugin/requirements.txt /home/dist/qpdf_plugin/requirements.txt',
                    'RUN pip3 install -r /home/dist/qpdf_plugin/requirements.txt',

                    'COPY {dist}/ml_test/requirements.txt /home/dist/ml_test/requirements.txt',
                    'RUN pip3 install -r /home/dist/ml_test/requirements.txt',
                ],
            },
        },
    },
}
