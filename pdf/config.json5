{
    // The workbench consists of UI connected to a number of external plugins,
    // which are organized into 'parsers', 'file_detail_views', and
    // 'decision_views'.  These are  supported through the defining of the
    // "build" environment.
    //
    // The reason this is a custom format instead of a standard Dockerfile is
    // so that the entire deployment might be specified in a single location.
    // Dockerfile is necessary because many external plugins have their own
    // requirements, etc.
    //
    // Everything in this file except 'build' is live-reloaded when used with
    // the --development flag. This applies mostly to plugins, but can also
    // apply to 'parsers' when the DB is reset through the UI (use on small
    // collections of files only).


    // The name of the docker image to be produced.
    name: 'galois-workbench-pdf',

    // Seconds in which all parsers must finish executing, when "Reprocess
    // DB Errors" is pressed (initial parserCombinedTimeout is always 60).
    // Half of this time is evenly divided amongst all parsers. The other half
    // is "flex" time allowed to the most expensive parser.
    parserCombinedTimeout: 7200,
    parsers: {
        // Example of running the unix command 'file' on each file to gather
        // information.
        "example-file": {
            // Any disabled parser has no effect -- comment this line to enable
            disabled: true,
            exec: ['file', '<inputFile>'],
            timeoutScale: 1,
            version: '1',
            parse: {
                type: 'regex-counter',
                stdstar: {
                  // Report all lines of stdout and stderr, but strip numbers.
                  '.*': {
                    nameReplace: {
                      '[0-9]': '',
                    },
                  },
                },
            },
        },

        // Definitions should follow old `invokers.cfg`, BUT eventually we also
        // want to specify `pdf-etl-parse` toolchain here.
        pdfinfo: {
            exec: ['/usr/local/bin/pdfinfo', '<inputFile>'],
            timeoutScale: 3,
            version: 'poppler-0.89.0',
            parse: {
                type: 'regex-counter',
                // The 'regex-counter' type generates a small program which
                // matches the parser's output line by line.
                // See https://docs.python.org/3/howto/regex.html for Regex
                // flavor. Counts are binary only.
                //
                // There are three parameters: 'stdstar', 'stdout', and
                // 'stderr'.
                //
                // 'stdstar' applies to both, and is tried after the
                // more-specific 'stdout' and 'stderr' arguments.
                stdout: {
                    '^File size: *(.*) bytes$': {
                      nameGroup: 'File size',
                      countGroup: 1,
                      countAsNumber: true,
                    },
                    '^([a-zA-Z0-9_ ]+): *(.*)$': {
                        nameGroup: 1,
                        nameReplace: {
                            '[0-9]': '',
                        },
                        countGroup: 2,
                        // countAsMissing can be used to
                        countAsMissing: ['no', 'none', '0', '0.0'],
                        // countAsNumber can be used to also add '_sum' to the
                        // database, which is handy for aggregating numeric
                        // values. Requires that `countGroup` points to
                        // a string which may be cast to a number, though.
                        //countAsNumber: true,
                    },

                    '.*': {
                        nameGroup: 'unrecognized',
                    },
                },
                stderr: {
                    '^(Syntax|Internal|Command Line) (Error|Warning)( \\([0-9]+\\))?: .*': {
                        nameReplace: {
                            '[0-9]': '',
                        },
                    },

                    '^Bogus.*': {
                    },
                },
            },
        },

        "pdfinfo-meta": {
            exec: ['/usr/local/bin/pdfinfo', '-meta', '<inputFile>'],
            timeoutScale: 3,
            version: 'poppler-0.89.0',
            parse: {
                type: 'regex-counter',
                stdstar: {
                    '.*': {
                        nameGroup: 'meta not implemented',
                    },
                },
            },
        },

        "pdfinfo-struct": {
            exec: ['/usr/local/bin/pdfinfo', '-struct', '<inputFile>'],
            timeoutScale: 18,
            version: 'poppler-0.89.0',
            parse: {
                type: 'regex-counter',
                stdout: {
                    '^[ \\t]*(/?[a-zA-Z][a-zA-Z0-9]*)( \\(block\\))?([ :]|$)': {
                        nameGroup: 'struct \\1\\2',
                    },
                    // These attributes may explode in count, but may be worth
                    // considering unique counts...
                    '(?P<type>/[a-zA-Z]+) (?P<amt>-?\\d+(\\.\\d+)?|/[A-Z][a-zA-Z]+)$': {
                        nameGroup: '\\g<type>',
                    },
                    // Anything else gets stripped
                    '.*': {
                        nameGroup: 'unrecognized',
                    },
                },
                stderr: {
                    '^(Syntax|Internal|Command Line) (Error|Warning)( \\([0-9]+\\))?: .*': {
                        nameReplace: {
                            '[0-9]': '',
                        },
                    },

                    '^Bogus.*': {
                    },
                },
            },
        },

        "pdfium": {
            exec: ['/opt/pdfium/pdfium_test', '<inputFile>'],
            timeoutScale: 18,
            version: 'chromium-4180',
            parse: {
                type: 'regex-counter',
                stdstar: {
                    '^.*$': {
                        nameReplace: {'[0-9]': ''},
                    },
                },
            },
        },

        "pdftocairo-pdf": {
            exec: ['/usr/local/bin/pdftocairo', '-pdf', '<inputFile>', '<tempFile>'],
            timeoutScale: 18,
            version: 'poppler-0.89.0',
            parse: {
                type: 'regex-counter',
                stderr: {
                    '.*': {
                        nameReplace: {'[0-9]': ''},
                    },
                },
            },
        },

        pdftops: {
            exec: ['/usr/local/bin/pdftops', '<inputFile>', '<tempFile>'],
            timeoutScale: 18,
            version: 'poppler-0.89.0',
            parse: {
                type: 'regex-counter',
                stdstar: {
                    '^.*$': {
                        nameReplace: {'[0-9]': ''},
                    },
                },
            },
        },

        pdftotext: {
          exec: ['bash', '-c', 'pdftotext $0 >(cat)', '<inputFile>'],
          timeoutScale: 18,
          version: 'pdftotext1',
          parse: {
            type: 'regex-counter',
            stdstar: {
              // We do NOT want the observatory to pick these up, so just ignore
              // every message. pdftotext must be searched via mongo!
              '^.*$': {
                nameGroup: '',
              },
            },
          },
        },

        polyfile: {
            // Prevent DB clutter
            exec: ['bash', '-c', "polyfile -m $0 2>&1 | grep 'Found a file of type'", '<inputFile>'],
            timeoutScale: 18,
            version: 'polyfile4',
            parse: {
              type: 'regex-counter',
              stdout: {
                '^Found a file of type.*': {
                  nameReplace: {'[0-9]': ''},
                },
                '^.*$': {
                  nameGroup: 'ignored stdout',
                },
              },
              stderr: {
                '^.*$': {
                  nameGroup: 'ignored stderr',
                },
              },
            },
        },

        'qpdf-check': {
            exec: ['qpdf', '--check', '<inputFile>'],
            timeoutScale: 18,
            version: '10.0.1',
            parse: {
                type: 'regex-counter',
                stdout: {
                    // Allowed / not allowed flags
                    '^([^:]+): (allowed|not allowed)$': {
                        nameGroup: 1,
                        countGroup: 2,
                        countAsMissing: ['not allowed'],
                    },

                    // Is file linearized?
                    '^[Ff]ile is (not )?([a-zA-Z]+)$': {
                        nameGroup: 'file is \\2',
                        countGroup: 1,
                        countAsMissing: ['not '],
                    },

                    // Copy errors without numbers...
                    '^ERROR: .*': {
                        nameReplace: {'[0-9]': ''},
                    },

                    // Copy warnings without numbers....
                    '^WARNING: .*': {
                        nameReplace: {'[0-9]': ''},
                    },

                    // Checking line is pointless
                    '^checking ': {
                        countReplace: {'.*': ''},
                    },

                    // As is this warning
                    '^(No syntax or stream encoding errors found; the file may still contain|errors that qpdf cannot detect)$': {
                        countReplace: {'.*': ''},
                    },

                    // PDF version
                    '^PDF Version': {
                        countReplace: {'.*': ''},
                    },

                    'end of.*section \\(/E\\) mismatch:': {
                        nameGroup: 'end of section mismatch',
                    },

                    // Unable to get object for item in shared objects hint
                    // table
                    '^unable to get .*': {
                    },

                    // Unexpected has a different format, like:
                    // page 1: page object 40 0 stream 1 0 (content, offset 126347): unexpected )
                    '.*: unexpected .+$': {
                        nameGroup: 'unexpected symbol: \\g<0>',
                        nameReplace: {'[0-9]': ''},
                    },

                    // Who knows what R or P or user password will be
                    '^([a-zA-Z0-9_ ]+?) *= *(.*)$': {
                        countReplace: {'.*': ''},
                    },

                    // QPDF has a lot of random error messages. Prefix them
                    // with ungrouped...
                    '.*': {
                        nameGroup: 'pdf-workbench ungrouped output: \\g<0>',
                        nameReplace: {'[0-9]': ''},
                    },
                },
                stderr: {
                    '^WARNING: .*?(pdf|\\)|[0-9]): (?P<warning>.*)$': {
                        nameGroup: 'WARNING: \\g<warning>',
                        nameReplace: {'[0-9]': ''},
                    },

                    '^.*?\\.pdf[ :](?P<warning>.*)$': {
                        nameGroup: 'pdf \\g<warning>',
                        nameReplace: {'[0-9]': ''},
                    },

                    '^qpdf: libqpdf/.*': {
                    },

                    '.*': {
                        nameGroup: 'pdf-etl-parse ungrouped error: \\g<0>',
                        nameReplace: {'[0-9]': ''},
                    },
                },
            },
        },

        'pdfid': {
            exec: ['python', 'lib/pdfid_v0_2_7/pdfid.py',
                // FIXME: a bit ugly that we have a relative path above
                '-e', '<inputFile>'],
            timeoutScale: 18,
            version: 'pdfid_v0_2_7',
            parse: {
                type: 'regex-counter',
                stdout: {
                    'pdf header:(.*)': {
                        nameGroup: 'PDF Header',
                    },

                    '^(.*?[Ee]ntropy.*):\\s*(\\d\\.\\d+)\\s+\\(\\s*(\\d+) bytes\\)$': {
                        nameGroup: 1,
                        countGroup: 2,
                    },

                    '^(.+?)[ \\t]+(\\d+)$': {
                        nameGroup: 1,
                        countGroup: 2,
                        countAsMissing: ['0', '0.', '0.0'],
                    },

                    '^[ \\t]*D:(\\d{14}).*(/[a-zA-Z0-9]+)$': {
                        nameGroup: 'Date: \\g<2>',
                    },

                    'PDFiD.*': {
                        countReplace: {'.*': ''},
                    },

                    '(.*)': {
                        nameGroup: 1,
                        nameReplace: {'[0-9]': ''},
                    },
                },
                stderr: {},
            },
        },

        'schizo-test': {
          exec: ['schizo_test/main.py', '<inputFile>'],
          timeoutScale: 18,
          version: 'schizo-test12',
          parse: {
            type: 'regex-counter',
            stdstar: {
              '^Max RMSE: (.*)': {
                nameGroup: 'Max RMSE',
                countGroup: 1,
                countAsNumber: true,
              },
              '^.*$': {
                nameReplace: {
                  '[0-9]': '',
                },
              },
            },
          },
        },

        'caradoc-stats': {
            exec: ['caradoc', 'stats', '<inputFile>'],
            timeoutScale: 18,
            version: 'caradoc-0.3',
            parse: {
                type: 'regex-counter',
                stdout: {
                    '^(([a-zA-Z ]|\\(s\\))+)$': {
                    },

                    '^\\s*(?P<key>.*) -> (?P<value>\\d+) times$': {
                        nameGroup: '\\g<key>',
                        countGroup: '\\g<value>',
                    },

                    '^\\s*(?P<key>[a-zA-Z/]+( [a-zA-Z]+)*)\\s*:\\s*(?P<value>.*)$': {
                        nameGroup: '\\g<key>',
                        countGroup: '\\g<value>',
                    },
                },
                stderr: {
                    '.*': {
                        nameReplace: {
                            '0x[0-9a-f]+b?|[0-9]': '',
                        },
                    },
                },
            },
        },

        'caradoc-strict': {
            exec: ['caradoc', 'stats', '--strict', '<inputFile>'],
            timeoutScale: 18,
            version: 'caradoc-0.3',
            parse: {
                type: 'regex-counter',
                stdout: {
                    '^(([a-zA-Z ]|\\(s\\))+)$': {
                    },

                    '^\\s*(?P<key>.*) -> (?P<value>\\d+) times$': {
                        nameGroup: '\\g<key>',
                        countGroup: '\\g<value>',
                    },

                    '^\\s*(?P<key>[a-zA-Z/]+( [a-zA-Z]+)*)\\s*:\\s*(?P<value>.*)$': {
                        nameGroup: '\\g<key>',
                        countGroup: '\\g<value>',
                    },
                },
                stderr: {
                    '.*': {
                        nameReplace: {
                            '0x[0-9a-f]+b?|[0-9]': '',
                        },
                    },
                },
            },
        },

        'mutool-convert-pdf': {
            exec: ['mutool', 'convert', '-F', 'pdf', '-o', '<tempFile .pdf>', '<inputFile>'],
            timeoutScale: 18,
            version: 'mupdf-1.17',
            parse: {
                type: 'regex-counter',
                stdout: {},
                stderr: {
                    '^.*$': {
                        nameReplace: {'[0-9]': ''},
                    },
                },
            },
        },

        'mutool-clean': {
            // "mutool clean -s" requires a .pdf extension, or it hangs
            exec: ['mutool', 'clean', '-s', '<inputFile>', '<tempFile .pdf>'],
            timeoutScale: 18,
            version: 'mupdf-1.17',
            parse: {
                type: 'regex-counter',
                stdout: {},
                stderr: {
                    '^.*$': {
                        nameReplace: {'[0-9]': ''},
                    },
                },
            },
        },

        'mutool-draw': {
            exec: ['mutool', 'draw', '-F', 'png', '-o', '<tempFile>', '<inputFile>'],
            timeoutScale: 18,
            version: 'mupdf-1.17',
            parse: {
                type: 'regex-counter',
                stdout: {},
                stderr: {
                    '^.*$': {
                        nameReplace: {'[0-9]': ''},
                    },
                },
            },
        },
    },

    decision_default: '\
# Any line beginning with a hash is a comment.  \n\
filters:  \n\
  # Filters are defined as groups of regular expressions.  \n\
\n\
  S1 all:  \n\
    # These are our filters from demo 1  \n\
    # A comment must not be inserted on the same line as a regular expression!  \n\
    ^caradoc-stats_[a-zA-Z0-9_/ ]+  \n\
    ^caradoc-strict_[a-zA-Z0-9_/ ]+  \n\
    ^pdfid[a-zA-Z0-9 _/%]+  \n\
    ^pdfid_Date:  \n\
    ^pdfinfo[a-zA-Z0-9 _]+  \n\
    ^pdfinfo-struct_Syntax Warning  \n\
    ^pdfinfo-struct_struct  \n\
    ^pdfinfo-meta_meta not implemented$  \n\
    ^qpdf-check_.*WARNING.*  \n\
    ^qpdf-check_[a-z ]+$  \n\
    ^mutool-clean_  \n\
    ^mutool-convert-pdf_  \n\
    <<workbench: Exit code  \n\
  \n\
  S2:  \n\
    # We\'ve talked about linearized files being unsafe...  \n\
    ^qpdf-check_file is linearized$  \n\
  \n\
  ValidMustHave:  \n\
    ^pdfid_%%EOF  \n\
  \n\
  ValidCannotHave:  \n\
    ^pdfinfo-struct_struct  \n\
    ^qpdf-check_.*ERROR.*  \n\
    ^qpdf-check_.*WARNING.*  \n\
  \n\
  ValidWarningsBad:  \n\
    ^caradoc-strict_PDF error : Xref table contains object that does not exist in object  \n\
    ^mutool-convert-pdf_error: cannot find .*  \n\
    ^mutool-convert-pdf_warning: non-page object in page tree  \n\
    ^mutool-convert-pdf_error: invalid key in dict  \n\
    ^mutool-convert-pdf_error: invalid indirect reference in dict  \n\
    ^mutool-convert-pdf_error: unknown token in dict  \n\
    #^mutool-convert-pdf_warning: cannot create ToUnicode mapping for  \n\
  \n\
  ValidWarningsXrefRebuild:  \n\
    ^qpdf-check_WARNING: xref not found  \n\
    ^pdfinfo-struct_Internal Error: xref num  not found but needed, try to reconstruct  \n\
    ^caradoc-strict_PDF error : Xref does not start at object  in object trailer at offset  \n\
    ^mutool-convert-pdf_warning: trying to repair broken xref  \n\
  \n\
  XrefIsAmbiguous:  \n\
    shared identifier entries  \n\
  \n\
  RejectedAmbiguousBad:  \n\
    ^qpdf-check_WARNING: loop detected following xref tables  \n\
    # This one is unreliable, and refers to previous lines in output ^mutool-convert-pdf_warning: unrecoverable error; ignoring rest of page  \n\
    ^mutool-convert-pdf_error: Unable to read ICC workflow  \n\
    # This one often applies to xref issues; ^mutool-convert-pdf_warning: repairing PDF document  \n\
    ^caradoc-stats_PDF error : Lexing error : integer error : integer overflow at offset  \n\
    ^mutool-convert-pdf_error: malformed page tree  \n\
  \n\
  RejectedBad:  \n\
    ^mutool-convert-pdf_error: no objects found  \n\
    ^caradoc-stats_PDF error : Lexing error : unexpected character : at offset  \n\
    ^pdfinfo-struct_Syntax Error \\(\\): Illegal character <> in hex string  \n\
    ^pdftocairo-pdf_Syntax Error \\(\\): Illegal character \'}\'  \n\
    ^pdftocairo-pdf_Syntax Error  \n\
    ^qpdf-check_WARNING: operation for dictionary attempted on object of type null: returning null for attempted key retrieval  \n\
    ^pdfinfo-struct_Syntax Error: Invalid object stream  \n\
  \n\
  SafeWarnings:  \n\
    ^qpdf-check_WARNING: unknown token while reading object; treating as string  \n\
    ^pdfid_/URI  \n\
    ^caradoc-stats_PDF error : Lexing error : integer error : integer overflow at offset  \n\
    ^caradoc-strict_PDF error : Xref does not start at object  in object trailer at offset  \n\
    After last %%EOF  \n\
    /Colors > 2^24  \n\
  \n\
  UnsafeWarnings:  \n\
    ^qpdf-check_WARNING: loop detected following xref tables  \n\
    ^pdfid_/OpenAction  \n\
    ^pdfinfo_Syntax Error \\(\\): Dictionary key must be a name object  \n\
    ^mutool-convert-pdf_warning: non-page object in page tree  \n\
    ^schizo\-test_Unable to read image  \n\
  \n\
  Unsafe: \n\
    ^polyfile_Found a file of type (?!Adobe Portable Document Format)  \n\
    ^schizo\-test_Schizophrenic:  \n\
  \n\
outputs:  \n\
  # Standard output status -- If a PDF passes filter S1, it will be "valid",  \n\
  # otherwise "rejected".  \n\
  status:  \n\
    "valid" is !(RejectedBad | RejectedAmbiguousBad | ValidWarningsXrefRebuild & XrefIsAmbiguous | Unsafe)  \n\
    "rejected" else  \n\
  \n\
  # Mark anything that is linearized as "rejected-unsafe", and otherwise  \n\
  # mark it as "valid".  \n\
  validity-status:  \n\
    "rejected" is RejectedBad  \n\
    "rejected-ambiguous" is RejectedAmbiguousBad | (ValidWarningsXrefRebuild & XrefIsAmbiguous)  \n\
    "valid-warnings" is ValidWarningsBad | !ValidMustHave | ValidCannotHave | ValidWarningsXrefRebuild  \n\
    "valid" else  \n\
    "rejected-unsafe"  \n\
  \n\
  safety-status:  \n\
    "unsafe" is Unsafe  \n\
    "unsafe-warnings" is UnsafeWarnings  \n\
    "safe-warnings" is SafeWarnings  \n\
    "safe" else  \n\
  ',

    decision_views: {
        /** Example decision process which documents API.

            See also build -> stages -> final, where the requirements for this
            plugin get installed.
            */
        qpdf_plugin: {
            // How this decider shows in the UI
            label: "Example - Allow QPDF Exit Code 0",
            // How this decider gets executed. 'program' is only option
            type: 'program',
            /** The commandline for invoking this program.

                stdout is expected to be a streaming JSON format, where each
                line is an object with keys:

                    * testfile: Full file name.
                    * info: Array of `'text'` or `{"description": "text",
                        "offset": <location specification>}`.
                    * <any>: A feature which should be specified in the
                        workbench DSL, in order to filter/interact with the
                        attribute.

                Lines not beginning with '{' are ignored.

                Options:

                * <filesPath> -- Path to folder containing files, in case this
                    decision process needs to look at the raw file data.

                * <jsonArguments> -- Receives a JSON object which contains any
                    parameters passed to this decider's URL. The workbench
                    itself will NOT use this feature, but the `<outputHtml>`
                    may leverage the value of `<workbenchApiUrl>` to re-run
                    a decision with new parameters, via e.g.
                    `workbenchApiUrl + '/decideAgain?arg1=1&arg2=2'` to
                    re-trigger this decider with
                    `jsonArguments={'arg1': '1', 'arg2': '2'}`.

                * <mongo> -- "host:port/db" pointer to the mongo database.

                    There are several available collections; the easiest to use
                    is `statsbyfile`, and the most detailed is `rawinvocations`.

                    Available collections:
                        * statsbyfile -- `_id` is path to file within
                            <filesPath>. Outside of that, each key is a
                            feature present in the file, and each value is
                            undefined at the moment.
                        * rawinvocations -- Keyed by `doc['invoker']['invName']`
                            and `doc['file']` (which is `filesPath + '/' + file`),
                            rawinvocations contains the raw parser stdout, stderr,
                            and exit code attained by running a parser.

                            Not for the faint of heart.

                * <outputHtml> -- Receives file path for customized debug display.
                    This file will be consumed and put into an iframe.

                * <workbenchApiUrl> -- Receives prefix for URL to access a file;
                    e.g., `url + 'showFile?id=' + statsbyfile['_id']` is the `href`
                    value for a link in the `outputHtml` file which would
                    lead the workbench to display the given file.

                    APIs:
                        * decide?arg1=1&arg2=2&... - Re-run this decision
                            plugin, with `<jsonArguments>` containing a dict:
                            `{'arg1': '1', 'arg2': '2'}`.
                        * showFile?id=file - Show details for `file` in the
                            workbench.

                    Javascript may be used to send arguments more complicated
                    than may be passed over a URL (as POST body).

                */
            exec: ['python3', 'qpdf_plugin/main.py', "<outputHtml>", "<workbenchApiUrl>", "<jsonArguments>"],
            /** Standard input passed to the program specified by `exec`. This is
                provided as a convenience, to prevent decision programs from
                needing to interact with mongo.

                Template substitution options:
                * <referenceDecisions> Each line is a JSON object, whose value
                    is one row of the current reference decision list.
                * <statsbyfile> Each line is a JSON object:
                    `{"_id": "file1", "feature1": <any>, ...}`.
                */
            execStdin: '<statsbyfile>',
        },

        vue_plugin: {
            label: 'Fancy Vue plugin',
            type: 'program',
            exec: ['python3', 'vue_plugin/main.py', '<outputHtml>',
                '<workbenchApiUrl>', '<jsonArguments>'],
            execStdin: '<statsbyfile>',
        },

        example2: {
            label: 'Flip reference decisions',
            type: 'program',
            exec: ['python3', '-c', "\
import json, sys \n\
with open(sys.argv[1], 'w') as html: \n\
    html.write('<html><body>') \n\
    in_refs = False \n\
    for line in sys.stdin: \n\
        if not in_refs: \n\
            if line == 'refs\\n': \n\
                in_refs = True \n\
        else: \n\
            o = json.loads(line) \n\
            o['status'] = 'valid' if o['status'] == 'rejected' else 'rejected' \n\
            print(json.dumps(o)) \n\
",
                    '<outputHtml>'],
            execStdin: 'lines\nblah\nrefs\n<referenceDecisions>',
        },
    },

    file_detail_views: {
        polyfile: {
            label: 'Polyfile',
            // 'type' denotes the way this detail view should be shown in the
            // UI, and how the underlying program gets run.  'program_to_html'
            // runs a program and opens '<outputFile>' in something like an
            // IFrame.
            type: 'program_to_html',
            exec: ['polyfile', '--html', '<outputFile>', '<inputFile>'],
        },

        schizo: {
            label: 'Schizophrenic Comparison',
            type: 'program_to_html',
            exec: ['schizo_test/main.py', '<inputFile>', '--html'],
        },

        viewer: {
            label: 'View PDF in browser',
            type: 'program_to_html',
            exec: ['cat', '<inputFile>'],
            // Applications may also produce non-HTML content displayable in a browser,
            // as long as the MIME type gets set. Test this in Chrome; Firefox appears
            // to have better MIME type inference, and may correctly show the content
            // even without this field.
            outputMimeType: 'application/pdf',
        },
    },

    build: {
        // The software environment must be defined.  It optionally may be grouped
        // into different build stages, which map to stages in docker.
        stages: {
            // Defining docker stages -- there MUST be a 'base' stage, which is
            // automatically included in final output.
            // Other stages with `copy_output` defined will also be included
            // in the final output.
            // Stages are written to the Dockerfile in order.  Most plugins will
            // only need to modify the 'final' stage's commands.

            // The base stage must have a 'from', which defines the base
            // image.  Other stages may also specify 'from'; otherwise,
            // `from: 'base'` is implied.

            // The 'final' stage is special -- it only allows commands, and
            // any commands executed are executed only in the final image.

            // Each stage may have a 'copy_output', which defines the outputs
            // produced by the stage.  The key is the absolute path to the file
            // or directory to be copied (may have asterisk wildcards), and the
            // value is either `true` to copy to the same absolute path, or a
            // new copy destination.  When specifying a new destination,
            // if that destination is a directory, append a trailing slash.

            // Each stage may have a 'commands', which specifies commands to
            // run.

            // Optimization note: every time 'base' gets updated, there may
            // be a long recompilation process. Ideally, most development work
            // should not touch 'base'. One way around this is for other images
            // to specify their own 'from' keys.

            base: {
                'from': 'ubuntu:18.04',
                commands: [
                    // Base packages
                    'RUN apt-get update && apt-get install -y \
                        curl \
                        python3 \
                        python3-pip \
                        xpdf \
                        wget \
                        ',
                    // Note that we will *also* install a newer version of poppler in /usr/local/bin
                    'RUN apt-get update && apt-get install -y \
                        poppler-utils \
                        ',
                    // Documented caradoc dependencies
                    'RUN apt-get update && apt-get install -y \
                        ocaml \
                        opam \
                        zlib1g-dev \
                        ',
                    // Undocumented caradoc dependencies
                    'RUN apt-get update && apt-get install -y \
                        m4 \
                        pkg-config \
                        libgmp3-dev \
                        ',
                    // Requirements for building poppler utils from source
                    // No effort has been made to distinguish what's required only
                    // for the build, so we install them all up front.
                    'RUN apt-get update && apt-get install -y \
                        uuid-dev \
                        gperf \
                        libtool \
                        gettext \
                        autopoint \
                        autoconf \
                        python3-dev \
                        libssl-dev \
                        cmake \
                        libfreetype6-dev \
                        libxcb-composite0-dev \
                        libxml2-dev \
                        ',
                    // Needed to build pdftocairo target in poppler
                    'RUN apt-get update && apt-get install -y \
                        libcairo2-dev \
                        ',
                    // Needed to build qpdf
                    'RUN apt-get update && apt-get install -y \
                        libjpeg-dev \
                        ',
                ],
            },

            // final is a special stage which runs in the final image.  Useful
            // for installing dependencies for downstream tools, without needing
            // to rebuild all of the other workbench internals.
            final: {
                commands: [
                    // Note that {dist} gets replaced in Dockerfile commands with
                    // the directory containing `config.json5`
                    'COPY {dist}/qpdf_plugin/requirements.txt /home/dist/qpdf_plugin/requirements.txt',
                    'COPY {dist}/schizo_test/requirements.txt /home/dist/schizo_test/requirements.txt',
                    'RUN pip3 install -r /home/dist/qpdf_plugin/requirements.txt',
                    'RUN pip3 install -r /home/dist/schizo_test/requirements.txt',
                    'RUN pip3 install polyfile',
                ],
            },

            caradoc: {
                from: 'base',
                copy_output: {
                    '/usr/local/bin/caradoc': true,
                },
                commands: [
                    'RUN opam init --auto-setup && opam install -y ocamlfind cryptokit ounit menhir',
                    'RUN \
                        wget -q https://github.com/ANSSI-FR/caradoc/raw/master/releases/caradoc-0.3.tar.gz \
                        && tar xf caradoc-0.3.tar.gz \
                        && rm caradoc-0.3.tar.gz \
                        ',
                    "RUN bash -c '\
                        cd caradoc-0.3 \
                        && eval `opam config env` \
                        && make \
                        && install caradoc /usr/local/bin \
                        '",
                ],
            },

            mupdf: {
                copy_output: {
                    '/usr/local/bin/mutool': true,
                },
                commands: [
                    'RUN \
                        wget -q https://mupdf.com/downloads/archive/mupdf-1.17.0-source.tar.gz \
                        && tar xf mupdf-1.17.0-source.tar.gz \
                        && rm mupdf-1.17.0-source.tar.gz \
                        ',
                    "RUN bash -c '\
                        cd mupdf-1.17.0-source \
                        && make XCFLAGS='-DDEBUG_PROGESSIVE_ADVANCE=1' tools\
                        && install build/release/mutool /usr/local/bin \
                        '",
                ],
            },

            pdfium: {
                copy_output: {
                  '/src/pdfium/pdfium/out/Workbench': '/opt/pdfium',
                },
                commands: [
                  'WORKDIR /src',
                  // Setup per https://pdfium.googlesource.com/pdfium/
                  'RUN git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git',
                  'ENV PATH /src/depot_tools:$PATH',
                  'RUN mkdir pdfium && cd pdfium && gclient config --unmanaged https://pdfium.googlesource.com/pdfium.git && gclient sync',
                  // Note the EDITOR= trick to populate the arbitrarily-specified file ... maybe could fill it in after gn exits, oh well
                  'RUN cd pdfium/pdfium \
                    && git checkout chromium/4260 \
                    && echo Not needed: ./build/install-build-deps.sh \
                    && EDITOR="python3 -c \'import sys; f = open(sys.argv[1], \\"w\\"); f.write(\\"pdf_is_standalone = true\\\\npdf_enable_xfa = true\\\\npdf_enable_v8 = true\\\\n\\"); f.close()\'" gn args out/Workbench \
                    && ninja -C out/Workbench pdfium_test \
                    ',
                ],
            },

            poppler: {
                copy_output: {
                    '/usr/local': '/usr/local',
                },
                commands: [
                    // ==== build freetype ====
                    'WORKDIR /src',

                    // FreeType http://www.linuxfromscratch.org/blfs/view/svn/general/freetype2.html
                    'RUN wget https://downloads.sourceforge.net/freetype/freetype-2.10.2.tar.xz',
                    'RUN tar -xvf freetype-2.10.2.tar.xz',

                    'WORKDIR /src/freetype-2.10.2',

                    // Some linux from scratch magic
                    'RUN sed -ri "s:.*(AUX_MODULES.*valid):\\1:" modules.cfg',
                    'RUN sed -r "s:.*(#.*SUBPIXEL_RENDERING) .*:\\1:" -i include/freetype/config/ftoption.h',
                    'RUN ./configure --prefix=/usr/local --enable-freetype-config',
                    'RUN make -j5 install',

                    // ==== build zlib ====
                    'WORKDIR /src',

                    // zlib
                    'RUN wget https://www.zlib.net/zlib-1.2.11.tar.gz',
                    'RUN tar -xzvf zlib-1.2.11.tar.gz',

                    'WORKDIR /src/zlib-1.2.11',
                    'RUN ./configure --prefix=/usr/local  && make -j$(nproc) test && make -j$(nproc) install',

                    // ==== build libxml ====
                    'WORKDIR /src',

                    // Libxml2
                    'RUN wget http://xmlsoft.org/sources/libxml2-2.9.10.tar.gz',
                    'RUN tar -xvf libxml2-2.9.10.tar.gz',

                    'WORKDIR /src/libxml2-2.9.10',
                    'RUN ./configure --prefix=/usr/local --with-python=/usr/bin/python3',
                    'RUN make -j5',
                    'RUN make install',

                    // ==== build fontconfig ====
                    'WORKDIR /src/',

                    'RUN wget https://www.freedesktop.org/software/fontconfig/release/fontconfig-2.13.92.tar.xz',
                    'RUN tar -xf fontconfig-2.13.92.tar.xz',

                    'WORKDIR /src/fontconfig-2.13.92/',

                    'RUN ./configure --sysconfdir=/etc --prefix=/usr/local --enable-libxml2 --mandir=/usr/local/share/man',
                    'RUN make -j5 install',

                    // ==== build poppler-utils ====
                    'WORKDIR /src/',

                    // Poppler 0.89.0
                    'RUN wget https://poppler.freedesktop.org/poppler-0.89.0.tar.xz',
                    'RUN tar -xvf poppler-0.89.0.tar.xz',

                    'WORKDIR /src/poppler-0.89.0',
                    // 'RUN cmake -DBUILD_SHARED_LIBS=OFF -DENABLE_LIBOPENJPEG=unmaintained -DCMAKE_CXX_COMPILER=clang++ -DCMAKE_C_COMPILER=clang ..',

                    'WORKDIR build',
                    'RUN cmake -DBUILD_SHARED_LIBS=OFF -DBUILD_GTK_TESTS=OFF -DBUILD_QT5_TESTS=OFF -DBUILD_CPP_TESTS=OFF -DENABLE_SPLASH=OFF -DENABLE_CPP=OFF -DENABLE_GLIB=OFF -DENABLE_GTK_DOC=OFF -DENABLE_QT5=OFF -DENABLE_LIBOPENJPEG=unmaintained -DENABLE_CMS=none -DENABLE_LIBCURL=OFF -DENABLE_ZLIB=OFF -DENABLE_DCTDECODER=unmaintained -DENABLE_ZLIB_UNCOMPRESS=OFF -DWITH_JPEG=OFF -DWITH_PNG=ON -DWITH_TIFF=OFF -DWITH_NSS3=OFF -DWITH_Cairo=ON -DWITH_FONTCONFIGURATION_FONTCONFIG=OFF -DCMAKE_EXE_LINKER_FLAGS="-pthread" ../',

                    // installs to /usr/local:
                    'RUN make -j5 install',
                ],
            },

            qpdf: {
                copy_output: {
                    '/usr/local': true,
                    '/usr/local/lib/libqpdf*': '/usr/lib/',
                                    // qdpf install is broken: efficient way around.
                },
                commands: [
                     'WORKDIR /src/',
                     'RUN \
                          wget https://github.com/qpdf/qpdf/archive/release-qpdf-10.0.1.tar.gz \
                          && tar xf release-qpdf-10.0.1.tar.gz \
                          && rm release-qpdf-10.0.1.tar.gz \
                          ',
                     'WORKDIR /src/qpdf-release-qpdf-10.0.1/',
                     'RUN ./configure',
                     'RUN make',
                     'RUN make install',
                ],
            },
        },
    },
}
