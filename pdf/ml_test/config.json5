{
  /* Configuration in subfolders gets merged into the base config with the
  following special rules:

  1. Most keys by default get merged if they are of an extensible type (list, map).
      Entries in 'parsers', 'file_detail_views', 'decision_views', and 'pipelines'
      must be entirely new keys.

  2. Docker build stages may match the names 'final' or 'base'. In both cases,
      specified 'commands' will be appended to the default config's commands.

  3. Any {dist} entries within the applicable parts (see main config.json5)
      will be replaced with the folder name containing the `config.json5`,
      instead of the base distribution directory. This may be used to, for
      example, fork a plugin and compare versions. Similarly, {disttarg} will
      be replaced with the in-docker path of the subfolder.

  4. Within any 'exec' entries, the current working directory will be set to
      the child directory instead of the distribution root.

      Within docker, this path will ALWAYS be within /home/dist, so it is
      decidable to find the sub path under which the distribution is running,
      if necessary.
  */
  build: {
    stages: {
      final: {
        commands: [
          'COPY {dist}/requirements.txt {disttarg}/requirements.txt',
          'RUN pip3 install -r {disttarg}/requirements.txt',
        ],
      },
    },
  },
  pipelines: {
    // Pipelines are the FAW's mechanism for dealing with parsers or other
    // reports which rely on the result of long-running tasks. For example, one
    // might want to use ML to learn a distribution over the data, and then
    // use the learned distribution to produce error messages.
    // Due to the complexity of this, and often the need for checkpointing and
    // re-entrant behavior, the FAW provides the pipeline framework. Pipelines
    // provide several entry points, each of which show up in the UI:
    //  1. Tasks, which do things like iterating through all files in
    //     randomized batches. Large data may be saved via an appropriate
    //     interface as specified by the <apiInfo> argument using e.g. GridFS.
    //  2. Parsers, which are the same as the top-level parsers but are
    //     declared with the pipeline so that the FAW might infer dependencies.
    //  3. The normal file-level and decision-level plugins which can generate
    //     reports based on the results of the pipeline.
    'ml-test': {
      label: "ML Test",
      // `disabled` can be omitted; if set to true, this pipeline and all of its
      // pieces will be disabled.
      disabled: false,
      // Tasks define a graph of work to be done for this pipeline.
      // Use the package provided at `import faw_pipeline_util` to explore
      // usage of <apiInfo>. `<apiInfo>` is used here due to the more
      // complicated communication between tasks and the FAW when compared to
      // file_detail_views and decision_views. (realistically, those could have
      // `<apiInfo>` added to simplify the interface)
      tasks: {
        learn: {
          // Changing this version triggers the task data to all be purged, and
          // re-runs this task and its dependents. In development mode, this
          // can happen mid-run.
          version: '12',
          // Tasks will automatically run until marked completed, unless
          // disabled.
          disabled: false,
          // This is the command line that gets run. Importantly, tasks have
          // the `<apiInfo>` parameter which may be passed. This will be a
          // JSON string which, after being decoded, should be passed to
          // an acceptable interface. In Python, this is the
          // `faw_pipelines_util.Api()` class.
          // If the task wants to do anything with files being inspected by the
          // FAW, then this parameter is crucial. It provides several interfaces,
          // `Api.file_list`/`Api.file_count` and `Api.file_sample`, each of
          // which may be used to enumerate files available to the FAW.
          // Those methods return internal paths; to actually access the files,
          // `Api.file_fetch` must be called within a `with` block, which will
          // return a local file path to a copy of the file being investigated.
          //
          // Any exit code of zero will signal success, and stop the task from
          // being run repeatedly. A non-zero response will result in the task
          // being re-run, assuming it is idempotent.
          //
          // See `cmd_train.py` and look at the usage of the `api` object for
          // additional tricks.
          //
          // IMPORTANT NOTE: this program gets run from a dask-worker. In other
          // words, it has no guarantees outside of the standard docker
          // environment used for this FAW distribution.
          //
          // To reload code during development, BE SURE TO TOUCH A CONFIG FILE!
          // That triggers dask processes to restart, which will load code
          // updates.
          exec: ['python3', 'main.py',
            '<apiInfo>',
            'train',
            '--header-bytes', '300',
            '--action_set-anchor_reward', '0.008',
            '--action_set-subgrammar_reward', '0.01',
            '--frequencies-tokens_per_decay', '5e4',
            '--net_context', '2',
            ],
          dependsOn: [
            // Suppose you have several long-running tasks, A and B. If B
            // depends on A, we may not always want to re-compute A when
            // debugging B. The FAW allows a pipeline multiple tasks for this
            // reason, and allows users to specify which tasks rely on one
            // another via the `dependsOn` list.
          ],
          // PYTHONPATH is set by default, but other environment variables
          // may be set:
          //env: {
          //  'PYTHONPATH': '{disttarg}:$PYTHONPATH',
          //},

          // May override; defaults to disttarg for all executed submodules.
          //cwd: '{disttarg}',
        },
      },
      // Same as top-level detail views; main difference is that these rely
      // on tasks (do they? HTML injection showing task progress?)
      file_detail_views: {
        showParse: {
          label: 'Show parse',
          type: 'program_to_html',
          exec: ['python3', 'main.py',
            '<apiInfo>', 'show_parse', '<outputHtml>', '<inputFile>'],
        },
      },
      decision_views: {
      },
      // Parsers depend on all tasks, and will only run after they all have
      // finished. Unless user presses a button?
      parsers: {
        'unique-rule-printer': {
          disabled: true,
          // TODO!!! Requires a means of accessing a Dask object... one can expose
          // a dask cluster via <apiInfo>. Perhaps can find an actor that way.
          // Can use `dask.distributed.fire_and_forget` to launch a temporary
          // actor which destroys itself after no usage... with a nanny task if
          // needed. In other words, all of that can happen within a normal
          // parser so long as we pass <apiInfo>
          timeout: 3600,
          exec: ['python3', 'main.py', '<apiInfo>', 'unique_rule_printer',
            '<inputFile>'],
          // Note that parsers within a pipeline still have their own version
          // field. This is to prevent needing to re-run tasks when developing
          // the parser component.
          version: '15',
          parse: {
              type: 'regex-counter',
              stdout: {
                '^(.*): (\\d+)$': {
                  nameGroup: 1,
                  countGroup: 2,
                  countAsNumber: true,
                },
              },
          },
        },
        'unique-bytes-printer': {
          disabled: true,
          exec: ['python3', 'main.py', '<apiInfo>', 'unique_bytes_printer',
            '<inputFile>'],
          version: '20',
          parse: {
              type: 'regex-counter',
              stdout: {
                '^(.*): (\\d+)$': {
                  nameGroup: 1,
                  countGroup: 2,
                  countAsNumber: true,
                },
              },
          },
        },
      },
    },
  },
}
